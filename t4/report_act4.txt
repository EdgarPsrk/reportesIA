%Preambulo--------------------------------------------------------------------
\documentclass[12pt,a4paper]{article}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage[margin=2cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{ragged2e}
\usepackage[font = footnotesize,labelfont=it]{caption}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{fontspec}
\usepackage{amsmath}
\usepackage[hidelinks]{hyperref}

%\setmainfont{Arial}
\pagestyle{empty}


%Inicio del documento---------------------------------------------------------
\begin{document}
	\begin{center}
		\textbf{\large{Implementación de un control para sistemas de reproducción utilizando visión artificial con redes neuronales convolucionales \\}}
		\footnotesize{Universidad Nacional Autónoma de México}\\
		\footnotesize{Facultad de Estudios Superiores Cuautitlán}\\
		\footnotesize{Alonso Vargas Gachuz}\\
		\footnotesize{Edgar Palomino Alfonso}
	\end{center}
	
	\begin{abstract}
	\end{abstract}
	
	\section{Introducción}
		Cualquier sistema en general agrupa una variedad de elementos los cuales desempeñan diferentes tareas que, en conjunto, son capaces de realizar procesos con gran complejidad. Para cualquier sistema será necesario otorgarle una entrada de la cual se esperará un resultado dependiendo del sistema ya que en algunos casos estas entradas pueden ser objetos o materia que debe ser procesada y en otros se debe manipular información con la cual se espera obtener otro tipo de resultados tal que estos sirvan para regular otros procesos consecuentes por ejemplo. Para que se pueda recolectar información, el sistema debe contar con sensores de los cuales obtendrá esa comunicación con el entorno que lo rodea de forma que pueda capturar toda la información necesaria para llegar a un resultado satisfactorio, con lo mencionado se puede concluir que cualquier sistema permanece aislado del entorno que lo rodea a menos que se le proporcione un medio para interactuar con su entorno.
		Los sistemas automatizados hacen uso de sensores con los cuales pueden mantener un control sobre el proceso que llevan a cabo, estos sensores convierten la información del medio físico en señales que pueda interpretar, el problema es que estas son limitadas sumado a que los sistemas no son capaces de inferir sobre los datos para obtener mejores resultados lo que se vuelven inadecuados en determinadas aplicaciones, una de ellas es el reconocimiento de objetos. La forma más utilizada para reconocer elementos del entorno es utilizando sensores de luz con los cuales se pueden llegar a identificar colores entre otros patrones, sin embargo, esto no es suficiente para dotar a un sistema la capacidad de reconocer patrones sobre 
		\newline\\
		
		
	\section{Estado del Arte}
	
	\section{Conocimientos previos}
	
	\section{Metodología}
	El planteamiento que se sigue en este documento se basa en el entrenamiento de la red You Only Look Once para la detección y reconocimiento de señas hechas con las manos a fin de reconocerlas y aplicarlas como comandos para el control de audio en un computador. A continuación se detallan los pasos realizados para entrenar y configurar la red.
	\subsection{Recolección y tratamiento de los datos}
	Las redes convolucionales requieren de una gran cantidad de información, al tener que trabajar con imágenes que poseen varias características es que a la red se le debe proporcionar diferentes datos para entrenamiento, con el fin de mejorar la precisión y confiabilidad en la red. Para este caso se necesita un conjunto particular de datos en los que se tengan determinadas posiciones en las manos, estas servirán para señalizar los controles de medios en el ordenador de las que se eligieron las siguientes propuestas: Mano totalmente abierta o cerrada para la reproducción o pausa, mano abierta con dedo pulgar retraído para aumentar el volumen y mano cerrada con pulgar estirado para reducir el volumen. Para la recolección se realizó un pequeño programa en Python el cual utiliza OpenCV para la captura de imágenes en tiempo real(\ref{create_dataset}), además de usar Mediapipe(Machine learning) para realizar un seguimiento de las manos, de modo que se pueda obtener una mejor captura y un tratamiento como: ajuste de resolución, medidas y encuadramiento para una mejor detección, se recolectaron en total 160 imágenes por cada señal, haciendo un total de 640 de las cuales se utilizaron 560 para el entrenamiento y 80 para validación. Concluida la tarea de recolección, pasamos al proceso de etiquetado, usando la herramienta labelme, remarcamos el contorno de cada imagen, añadiendo las correspondientes etiquetas(\ref{label_prcss}).
	\begin{figure}[!h]
		\begin{subfigure}[b]{1\textwidth}
			\centering
			\includegraphics[scale = 0.35]{create_dst}
			\caption{Captura de imágenes}
			\label{create_dataset}
			\hfill
		\end{subfigure}
		
		\begin{subfigure}[b]{1\textwidth}
			\centering
			\includegraphics[scale = 0.35]{label_procss}
			\caption{Remarcado y etiquetado}
			\label{label_prcss}
			\hfill
		\end{subfigure}
		\caption{Proceso de creación del set de datos}
	\end{figure}
	\\
	Al remarcar y etiquetar las imágenes, la herramienta labelme generará un archivo tipo JSON, dónde se encuentran las etiquetas y los puntos generados previamente, además de incluir algunos otros datos, sin embargo, la red YOLO unicamente acepta el formato .txt donde se indiquen los puntos remarcados en el proceso de etiquetado. Para hacer la conversión se utilizó la herramienta labelme2yolo la cual realiza esta tarea de forma automática. Al usar la herramienta nos arrojará una carpeta con dos carpetas dentro y un archivo de tipo yaml. Las carpetas generadas contienen las imágenes del set de datos y las etiquetas generadas con extensión .txt, el archivo yaml es requerido por la red, tiene el objetivo de indicarle donde encontrar los archivos de entrenamiento y validación respectivamente.
	\subsection{Entrenamiento de la red neuronal}
	Con el set de datos completo, podemos proceder al entrenamiento de la red neuronal YOLO, para comenzar es necesario conseguir la librería Ultralytics de Python, dónde obtendremos la herramienta para el entrenamiento, opcionalmente se puede instalar PyTorch con la cual es posible trabajar utilizando la tarjeta gráfica del computador, acelerando el proceso de entrenamiento, aunque se puede optar por usar la CPU en este caso se opto por incluirlo. Para comenzar el entrenamiento utilizamos el comando yolo, indicándole los parámetros deseados para comenzar el entrenamiento(\ref{yolo_train}).\\
	
	\begin{figure}[!h]
		\centering
		\includegraphics[scale=0.6]{yolo_comand}
		\caption{Proceso de entrenamiento de la red YOLO, en los parámetros se indican de izquierda a derecha: tarea de segmentación, modo de entrenamiento, 60 épocas, ruta del set de datos, versión requerida, resolución de las imágenes y cantidad de imágenes para la tarea}
		\label{yolo_train}
	\end{figure}
	Este proceso arrojará una carpeta donde se tendrán los resultados del entrenamiento, mostrando la matriz de confusión, las gráficas de precisión, una carpeta con los archivos de pesos obtenidos del entrenamiento, algunas de las imágenes para la validación entre otras cosas útiles para el análisis de los resultados. Lo más importante dentro de la carpeta son los archivos que contienen los pesos cuya extensión es .pt, existen dos archivos los cuales son best y last, siendo el archivo best quien contiene los pesos que entregan mejores resultados. 
	
	\subsection{Control de medios}
	Existe una gran cantidad de librerías que proporciona la comunidad de Python, entre estas existen algunas que nos brindan control sobre las funcionalidades del sistema operativo y sobre los medios. Como primera instancia se realizó un programa para el control del audio maestro en el ordenador utilizando la librería pycaw, la cual otorga algunos métodos sobre el control de audio. Otra librería importante es pyautogui la cual permite simular algunas opciones de teclas usadas en el sistema operativo, usándola podemos simular el control del botón play/pause, uno de los comandos por defecto de teclado que nos entregará el control de reproducción sobre cualquier aplicación que reproduzca audio en el ordenador.
	\lstinputlisting[language=Python]{audio.py}
	En resumen, el código obtiene el parámetro requerido que puede ser cualquiera de las 4 opciones(reproducción, pausa, subir o bajar volumen), en función de dicha entrada realizará una de dichas acciones, la entrada es resultante del proceso de predicción de la red neuronal entrenada.
	
	\subsection{Pruebas de funcionamiento}
	Al conseguir los pesos para la red neuronal, es posible exportarlos para realizar pruebas, la librería Ultralytics permite instanciar el modelo en un objeto, este solo requiere de dichos pesos para poder funcionar de acuerdo al entrenamiento realizado. Para hacer las pruebas nuevamente se realizó un seguimiento de la mano para obtener mejores entradas y que se adecuaran con los datos de entrenamiento, estas fueron pasadas al modelo y con ayuda de las funciones del mismo, se obtuvieron las predicciones al mostrarlas en la pantalla junto con el seguimiento de la mano.\\
	\begin{figure}[!h]
		\begin{subfigure}[b]{0.5\textwidth}
			\includegraphics[scale=0.3]{test_yolo}
			\caption{Prueba para play}
			\label{play}
			\hfill
		\end{subfigure}
		\begin{subfigure}[b]{0.5\textwidth}
			\includegraphics[scale=0.35]{test_yolo1}
			\caption{Prueba para pause}
			\label{pause}
			\hfill
		\end{subfigure}
		\begin{subfigure}[b]{0.5\textwidth}
			\includegraphics[scale=0.3]{test_yolo2}
			\caption{Prueba para V-}
			\label{v+}
			\hfill
		\end{subfigure}
		\begin{subfigure}[b]{0.5\textwidth}
			\includegraphics[scale=0.35]{yolo_test3}
			\caption{Prueba para V+}
			\label{v-}
			\hfill
		\end{subfigure}
		\caption{Resultados de las predicciones del modelo entrenado}
	\end{figure}
	\subsection{Implementación de resultados}
	Comprobado el funcionamiento, se procedió a implementar la red de modo que controlara los medios del ordenador, para verificar el funcionamiento más adecuadamente, se empleó una pantalla LCD en la cual se despliegan las opciones detectadas por la red, de modo que, cuando se detecta una opción, un microcontrolador desplegará en un LCD la conclusión obtenida.
	\begin{figure}[!h]
		\begin{subfigure}[b]{0.5\textwidth}
			\includegraphics[scale = 1.18]{ard_1}
			\caption{Acción de reproducción/pausa}
		\end{subfigure}
		\begin{subfigure}[b]{0.5\textwidth}
			\includegraphics{ard_2}
			\caption{Reducción del volumen}
		\end{subfigure}
		\begin{subfigure}[b]{1\textwidth}
			\centering
			\includegraphics{ard_3}
			\caption{Aumento de volumen}
		\end{subfigure}
		\caption{Pruebas con el LCD}
	\end{figure}
	\newpage
	\section{Análisis de resultados}
	La herramienta para el entrenamiento proporciona en su salida una serie de archivos con los resultados del entrenamiento, dichos elementos hacen más fácil el análisis detallado sobre el desempeño de la red neuronal.
	Primero hay que analizar las curvas de confianza.
	\begin{figure}[!h]
		\begin{subfigure}[b]{1\textwidth}
			\centering
			\includegraphics[scale = 0.35]{BoxF1_curve}
			\label{F1_curve}
			\caption{Curva de confianza y exactitud del modelo}
		\end{subfigure}
		\begin{subfigure}[b]{1\textwidth}
			\centering
			\includegraphics[scale = 0.3]{BoxP_curve}
			\label{P_curve}
			\caption{Curva de confianza y precisión del modelo}
		\end{subfigure}
		\caption{Curvas de confianza}
	\end{figure}
	Con estas gráficas es posible visualizar que la exactitud del modelo aumenta cuando el valor de confianza es bajo en la mayoría de los casos y que la precisión aumenta cuando la confianza del modelo es mayor, sobre la gráfica de exactitud podemos concluir en que ciertos traslapes en la identificación de las formas, lo cual es entendible pues de cierta forma son muy parecidas las formas que debe identificar como cuando la mano está totalmente abierta y cuando la mano está abierta pero con el pulgar enroscado, por lo que existirá cierto traslape en algunas de las posiciones donde habrá error, para mejorar el reconocimiento se debería optar por añadir más imágenes para el entrenamiento, ya que 140 son bastante pocas.
	
	
\end{document}